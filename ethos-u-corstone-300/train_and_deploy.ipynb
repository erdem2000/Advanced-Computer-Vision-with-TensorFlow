{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erdem2000/Advanced-Computer-Vision-with-TensorFlow/blob/master/ethos-u-corstone-300/train_and_deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ5wp8jvZVWE"
      },
      "outputs": [],
      "source": [
        "#  Copyright (c) 2021 Arm Limited. All rights reserved.\n",
        "#  SPDX-License-Identifier: Apache-2.0\n",
        "#\n",
        "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#  you may not use this file except in compliance with the License.\n",
        "#  You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "#  Unless required by applicable law or agreed to in writing, software\n",
        "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#  See the License for the specific language governing permissions and\n",
        "#  limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbfsgUcBG_hx"
      },
      "source": [
        "# Train and Deploy your NPU-enabled models\n",
        "\n",
        "> Using the Arm Corstone-300 with Cortex-M55 and Ethos-U55."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jty-u4JWHViE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook presents a flow to help bridge the gap between data scientists and embedded engineers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOvd37uuHTE7"
      },
      "source": [
        "## Training a Model\n",
        "\n",
        "In this example we are going to train a \"toy\" model. We will create a basic convolutional neural network model to solve the MNIST problem.\n",
        "\n",
        "The [MNIST database](http://yann.lecun.com/exdb/mnist/) is a dataset of handwritten digits which can be used to train a digit classifier. It is often used as a starter dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EatvozlIIlO"
      },
      "source": [
        "Let's start of by importing the required Python dependencies. For this we will use the [TensorFlow](https://github.com/tensorflow/tensorflow) framework for the model and [TensorFlow Datasets](https://github.com/tensorflow/datasets) to download the MNIST dataset. If you're using Google Colab, these dependencies come preinstalled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3CjmqOzKBY5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJFi-du1IGLt"
      },
      "source": [
        "We can now download the MNIST dataset using TensorFlow datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1LDNN4CKJNJ"
      },
      "outputs": [],
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load('mnist', split=['train', 'test'], shuffle_files=True,\n",
        "  as_supervised=True, with_info=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv_Oq-qbekcD"
      },
      "source": [
        "Once downloaded, we write a function to preprocess the MNIST dataset ready for use in a neural network. The images come in `uint8` format, and so to normalize the dataset so that all values are between `[0, 1]` we divde by `255` (the max `uint8` value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2WykZXvKMcB"
      },
      "outputs": [],
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOHsvHJFfBZK"
      },
      "source": [
        "Let's apply this function to the dataset using `.map` and take a batch size of `128`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9ifl7ztLp-K"
      },
      "outputs": [],
      "source": [
        "ds_train = ds_train.map(\n",
        "  normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "  normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0CIYup1fP3j"
      },
      "source": [
        "We are now ready to create the model using the `Sequential` functionality.\n",
        "\n",
        "Although we could achieve a model with high accuracy using a fully connected model, this would require a lot of weights and biases. The Ethos-U55 is designed to be used with a Cortex-M55 meaning there will be memory limits. For this reason we build a convolutional network with large kernel sizes to reduce the number of weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXs4ohIBLtJs"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iC85LSpgcW5"
      },
      "source": [
        "We are now ready to train the model. For this toy example we will just train for a singular epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hQWCshvgh3X"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(ds_train, epochs=1, validation_data=ds_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWWHoEwEgrgn"
      },
      "source": [
        "## Quantize the Model\n",
        "\n",
        "The next step is to quantize the model. This converts the weights from floating-point numbers to integer numbers. The Ethos-U55 supports 8 bit weights, and 8 bit and 16 bit activations.\n",
        "\n",
        "In this example we will quantize the model into `int8` format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itj03AI3g-3u"
      },
      "source": [
        "Let's first `unbatch` the dataset from 128 samples at a time. In inference we will only be running one image at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6mQX5slMVRi"
      },
      "outputs": [],
      "source": [
        "ds_train = ds_train.unbatch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F16ebTLfhIbS"
      },
      "source": [
        "We can then build a generator function to use in the conversion process.\n",
        "\n",
        "Creating a generator allows the TensorFlow Lite converter find the best weights to fall to based on the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK0O6BZxhHvW"
      },
      "outputs": [],
      "source": [
        "def representative_data_gen():\n",
        "  for input_value, output_value in ds_train.batch(1).take(100):\n",
        "    yield [input_value]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cu6-dIGhUOR"
      },
      "source": [
        "Finally we are ready to convert the model. We can use the `from_keras_model` method to create a converter from our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G74vW7fHhWwO"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cseaAGpahiGw"
      },
      "source": [
        "We can then set the `inference_input_type`, `inference_output_type` and `supported_ops` to `int8`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfERi-ZihhnQ"
      },
      "outputs": [],
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFkw1yKeh9MR"
      },
      "source": [
        "We then add the `representative_dataset` to be our generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51eB1Qcph5fP"
      },
      "outputs": [],
      "source": [
        "converter.representative_dataset = representative_data_gen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ9plu3riC8S"
      },
      "source": [
        "The last step is to run the conversion process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dJDoeRYiDXW"
      },
      "outputs": [],
      "source": [
        "tflite_model_quant = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G02dEuPeiG87"
      },
      "source": [
        "We now have a quantized model in TFLite format. Let's save this to our files as `my_model.tflite`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0fUWRdtNd2S"
      },
      "outputs": [],
      "source": [
        "with open(\"my_model.tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model_quant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "freVF5X5iZOm"
      },
      "source": [
        "## Vela Compiler\n",
        "\n",
        "When creating a model for use on Ethos-U55 we need to use the Vela Compiler to optimise the model.\n",
        "\n",
        "This is a command-line tool written in Python which takes a `.tflite` file and outputs another `.tflite` file. The new file is restructured in a way that Ethos-U understands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSWWZxa3jHqN"
      },
      "source": [
        "To do this, let's first install `ethos-u-vela` for the compiler and `xxd` which will be used to convert binary files into hexdumps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhxBhPy2Lw_e"
      },
      "outputs": [],
      "source": [
        "!pip install ethos-u-vela\n",
        "!apt install -y xxd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYnCP6FjkRL"
      },
      "source": [
        "We can now compile the model. For this we will specify the config as `ethos-u55-128`. This is one of the commonly used templates for Ethos-U55. This configuration has 128 macs. We will create a `vela.ini` file with our system configuration description. This information helps vela to optimize model efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HowtNadlZVW-"
      },
      "outputs": [],
      "source": [
        "%%writefile vela.ini\n",
        "\n",
        "[System_Config.Ethos_U55_High_End_Embedded]\n",
        "core_clock=500e6\n",
        "axi0_port=Sram\n",
        "axi1_port=OffChipFlash\n",
        "Sram_clock_scale=1.0\n",
        "Sram_burst_length=32\n",
        "Sram_read_latency=32\n",
        "Sram_write_latency=32\n",
        "OffChipFlash_clock_scale=0.125\n",
        "OffChipFlash_burst_length=128\n",
        "OffChipFlash_read_latency=64\n",
        "OffChipFlash_write_latency=64\n",
        "\n",
        "; Shared SRAM: the SRAM is shared between the Ethos-U and the Cortex-M software\n",
        "; The non-SRAM memory is assumed to be read-only\n",
        "[Memory_Mode.Shared_Sram]\n",
        "const_mem_area=Axi1\n",
        "arena_mem_area=Axi0\n",
        "cache_mem_area=Axi0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfaE1o5VTLmm"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "vela --accelerator-config=ethos-u55-128 \\\n",
        "--optimise Performance \\\n",
        "--memory-mode=Shared_Sram \\\n",
        "--system-config=Ethos_U55_High_End_Embedded \\\n",
        "--config vela.ini \\\n",
        "my_model.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiNyZX9lj1Oe"
      },
      "source": [
        "We can then convert the `.tflite` binary into a hexdump C headerfile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f-vZlyhj0rm"
      },
      "outputs": [],
      "source": [
        "!xxd -i output/my_model_vela.tflite my_network_model.h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HceA9y8Oj_hF"
      },
      "source": [
        "The last step is to do some cleaning up of the file for the application. Here we rename the model from `output_my_model_vela_tflite` to `network_model` and add some header guards to the file.\n",
        "\n",
        "The most important is to add model variable attribute `__attribute__((aligned(16)))` for 16 bytes alignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t2Y0Aapj_N3"
      },
      "outputs": [],
      "source": [
        "!sed -i 's/unsigned int output_my_model_vela_tflite_len/const unsigned int network_model_len/' my_network_model.h\n",
        "!sed -i 's/unsigned char output_my_model_vela_tflite\\[\\]/const unsigned char network_model\\[\\] __attribute__((aligned(16)))/' my_network_model.h\n",
        "\n",
        "!sed -i '1s/^/#define NETWORK_MODEL_H\\n/' my_network_model.h\n",
        "!sed -i '1s/^/#ifndef NETWORK_MODEL_H\\n/' my_network_model.h\n",
        "!echo \"#endif //NETWORK_MODEL_H\" >> my_network_model.h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r93Zxt3rIrum"
      },
      "source": [
        "## Build the application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV9WkffSkwtK"
      },
      "source": [
        "With the model now ready to use in the application, we need to generate some test data to use in the model. To do this we create two functions, `write_input_headerfile` which writes an example input array to a headerfile and `write_output_headerfile` which writes the expected output array to the headerfile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYiiG831BwRh"
      },
      "outputs": [],
      "source": [
        "def write_input_headerfile(array):\n",
        "  with open(\"input_data.h\", \"w\") as f:\n",
        "    line = \"#ifndef INPUT_DATA_H\\n#define INPUT_DATA_H\\n\\n\"\n",
        "    f.write(line)\n",
        "    line = f\"static const int input_data_len = {len(array)};\\n\"\n",
        "    f.write(line)\n",
        "    line = \"static const int8_t input_data[] = {\\n  \"\n",
        "    f.write(line)\n",
        "    count = 0\n",
        "    for val in array:\n",
        "      if (count+1)%8 == 0:\n",
        "        line = f\"{val},\\n  \"\n",
        "      else:\n",
        "        line = f\"{val}, \"\n",
        "      count += 1\n",
        "      if count == len(array):\n",
        "        line = line.replace(\",\",\"\")\n",
        "      f.write(line)\n",
        "    line = \"\\n};\\n\\n\"\n",
        "    f.write(line)\n",
        "    line = \"#endif // INPUT_DATA_H\"\n",
        "    f.write(line)\n",
        "\n",
        "  return None\n",
        "\n",
        "def write_output_headerfile(array):\n",
        "  with open(\"expected_output_data.h\", \"w\") as f:\n",
        "    line = \"#ifndef EXPECTED_OUTPUT_DATA_H\\n#define EXPECTED_OUTPUT_DATA_H\\n\\n\"\n",
        "    f.write(line)\n",
        "    line = f\"static const int expected_output_data_len = {len(array)};\\n\"\n",
        "    f.write(line)\n",
        "    line = \"static const int8_t expected_output_data[] = {\\n  \"\n",
        "    f.write(line)\n",
        "    count = 0\n",
        "    for val in array:\n",
        "      if (count+1)%8 ==0:\n",
        "        line = f\"{val},\\n  \"\n",
        "      else:\n",
        "        line = f\"{val}, \"\n",
        "      count += 1\n",
        "      if count == len(array):\n",
        "        line = line.replace(\",\",\"\")\n",
        "      f.write(line)\n",
        "\n",
        "    line = \"\\n};\\n\\n\"\n",
        "    f.write(line)\n",
        "    line = \"#endif // EXPECTED_OUTPUT_DATA_H\"\n",
        "    f.write(line)\n",
        "\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8fTiaEQlGWu"
      },
      "source": [
        "Let's take an input from a test set for use in the application:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbE-ckxzTuiL"
      },
      "outputs": [],
      "source": [
        "# Load the model into tflite\n",
        "tflite_model = tf.lite.Interpreter(\"my_model.tflite\")\n",
        "\n",
        "# Get the input and output information from the model\n",
        "input_details = tflite_model.get_input_details()\n",
        "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
        "output_details = tflite_model.get_output_details()\n",
        "\n",
        "# Unbatch the test dataset\n",
        "ds_test = ds_test.unbatch()\n",
        "\n",
        "# Take one example from the test set\n",
        "for x,y in ds_test.batch(1).take(1):\n",
        "  # Convert the input to a numpy array\n",
        "  x_numpy = x.numpy()\n",
        "  # Quantize the input data into int8 format\n",
        "  x_numpy = x_numpy / input_scale + input_zero_point\n",
        "  x_numpy = x_numpy.astype(input_details[0][\"dtype\"])\n",
        "  # Write the array to a headerfile\n",
        "  write_input_headerfile(x_numpy.flatten())\n",
        "\n",
        "  # Run the model to get the expected output\n",
        "  tflite_model.allocate_tensors()\n",
        "  #tflite_model.set_tensor(input_details[0]['index'], np.expand_dims(x_numpy,axis=0))\n",
        "  tflite_model.set_tensor(input_details[0]['index'], x_numpy)\n",
        "  tflite_model.invoke()\n",
        "\n",
        "  # Get the output array from the model\n",
        "  output_data = tflite_model.get_tensor(output_details[0][\"index\"])\n",
        "  # Write the headerfile for the expected output\n",
        "  write_output_headerfile(output_data.flatten())\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aq7hrxnl4Tn"
      },
      "source": [
        "With everything now ready to build the application we can start downloading the dependencies for the application. We first download the `tflite-micro` repository and checkout specific tested commit. Then remove unnecessary default model download from the generation scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zHVbrxgpQuD"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "git clone https://github.com/tensorflow/tflite-micro.git\n",
        "cd tflite-micro\n",
        "git checkout 080db2db55e82863d1a9adcf5c045d48e3e73941\n",
        "\n",
        "sed -i '58,62d' tensorflow/lite/micro/tools/make/ext_libs/ethos_u.inc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO7U1QGdEN53"
      },
      "source": [
        "Now we generate the TensorFlow Lite Micro (TFLite-Micro) library for use in our application. To do this we set the target as the `cortex_m_corstone_300` which has been built into TFLite-Micro, the architecture as `cortex-m55`, the `CO_PROCESSOR=ethos_u` tag enabled Ethos-U kernels in the library and finally we use `cmsis_nn` to provide optimized kernels for Cortex-M55:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZPMEMAvoRvI"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "cd tflite-micro\n",
        "make -f tensorflow/lite/micro/tools/make/Makefile third_party_downloads\n",
        "make -f tensorflow/lite/micro/tools/make/Makefile \\\n",
        "TARGET=cortex_m_corstone_300 \\\n",
        "TARGET_ARCH=cortex-m55 \\\n",
        "CO_PROCESSOR=ethos_u \\\n",
        "OPTIMIZED_KERNEL_DIR=cmsis_nn \\\n",
        "microlite -j8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSLr2x6koeUn"
      },
      "source": [
        "We now have a compiled Tensorflow micro library file called `libtensorflow-microlite.a`.\n",
        "\n",
        "Let's now write the application using Tensorflow micro test framework. This is a testing application which will compare the output with the expected output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAhQhxdYEuUg"
      },
      "outputs": [],
      "source": [
        "%%writefile main.cc\n",
        "\n",
        "#include \"tensorflow/lite/micro/micro_error_reporter.h\"\n",
        "#include \"tensorflow/lite/micro/micro_interpreter.h\"\n",
        "#include \"tensorflow/lite/micro/micro_utils.h\"\n",
        "#include \"tensorflow/lite/micro/testing/micro_test.h\"\n",
        "#include \"tensorflow/lite/schema/schema_generated.h\"\n",
        "#include \"tensorflow/lite/micro/micro_mutable_op_resolver.h\"\n",
        "\n",
        "#include \"my_network_model.h\"\n",
        "#include \"input_data.h\"\n",
        "#include \"expected_output_data.h\"\n",
        "\n",
        "#define TENSOR_ARENA_SIZE (70 * 1024)\n",
        "\n",
        "uint8_t tensor_arena[TENSOR_ARENA_SIZE];\n",
        "\n",
        "TF_LITE_MICRO_TESTS_BEGIN\n",
        "\n",
        "TF_LITE_MICRO_TEST(TestInvoke) {\n",
        "\n",
        "  tflite::MicroErrorReporter micro_error_reporter;\n",
        "  // load the model\n",
        "  const tflite::Model* model = ::tflite::GetModel(network_model);\n",
        "  if (model->version() != TFLITE_SCHEMA_VERSION) {\n",
        "    TF_LITE_REPORT_ERROR(&micro_error_reporter,\n",
        "                         \"Model provided is schema version %d not equal \"\n",
        "                         \"to supported version %d.\\n\",\n",
        "                         model->version(), TFLITE_SCHEMA_VERSION);\n",
        "    return kTfLiteError;\n",
        "  }\n",
        "\n",
        "  TF_LITE_REPORT_ERROR(&micro_error_reporter, \"Hello TFLITE Micro Tests.\\n\");\n",
        "  tflite::MicroMutableOpResolver<1> micro_op_resolver;\n",
        "  //tell tensorflow micro to add ethos-u operator\n",
        "  micro_op_resolver.AddEthosU();\n",
        "\n",
        "  tflite::MicroInterpreter interpreter(\n",
        "      model, micro_op_resolver, tensor_arena, TENSOR_ARENA_SIZE, &micro_error_reporter);\n",
        "\n",
        "  TfLiteStatus allocate_status = interpreter.AllocateTensors();\n",
        "  if (allocate_status != kTfLiteOk) {\n",
        "    TF_LITE_REPORT_ERROR(&micro_error_reporter, \"Tensor allocation failed\\n\");\n",
        "    return kTfLiteError;\n",
        "  }\n",
        "\n",
        "  TfLiteTensor* input = interpreter.input(0);\n",
        "  TfLiteTensor* output = interpreter.output(0);\n",
        "\n",
        "  memcpy(input->data.int8, &input_data, input->bytes);\n",
        "\n",
        "  TfLiteStatus invoke_status = interpreter.Invoke();\n",
        "\n",
        "  if (invoke_status != kTfLiteOk) {\n",
        "    TF_LITE_REPORT_ERROR(&micro_error_reporter, \"Invoke failed\\n\");\n",
        "      return kTfLiteError;\n",
        "  }\n",
        "  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, invoke_status);\n",
        "\n",
        "  for (int i=0; i < expected_output_data_len; i++) {\n",
        "    TF_LITE_MICRO_EXPECT_EQ(output->data.int8[i], expected_output_data[i]);\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "TF_LITE_MICRO_TESTS_END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHU49uFpp6ol"
      },
      "source": [
        "and the `Makefile` used to build the application:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rxhwbcsI3cN"
      },
      "outputs": [],
      "source": [
        "%%writefile Makefile\n",
        "\n",
        "TFLM_ROOT := tflite-micro/tensorflow/lite/micro\n",
        "THIRD_PARTY := $(TFLM_ROOT)/tools/make/downloads\n",
        "TARGET := cortex_m_corstone_300\n",
        "TARGET_CPU := cortex-m55\n",
        "\n",
        "\n",
        "CXX := $(TFLM_ROOT)/tools/make/downloads/gcc_embedded/bin/arm-none-eabi-g++\n",
        "\n",
        "INCLUDES := -I$(TFLM_ROOT)/../../..\\\n",
        "  -I. \\\n",
        "  -I$(THIRD_PARTY)/flatbuffers/include\n",
        "\n",
        "\n",
        "CXXFLAGS := -std=c++11 -O3 -mfloat-abi=hard -mlittle-endian -MD -mcpu=cortex-m55 -mfpu=auto -mthumb \\\n",
        "    -Werror -Wvla -Wall -Wextra -funsigned-char -fno-function-sections \\\n",
        "    -fno-rtti -fno-exceptions -fno-threadsafe-statics -fno-unwind-tables -ffunction-sections \\\n",
        "    -fdata-sections -Wno-unused-parameter -DTF_LITE_STATIC_MEMORY\n",
        "\n",
        "\n",
        "OBJCOPY := $(TFLM_ROOT)/tools/make/downloads/gcc_embedded/bin/arm-none-eabi-objcopy\n",
        "\n",
        "\n",
        "LDFLAGS := -lm\\\n",
        "  $(TFLM_ROOT)/tools/make/gen/$(TARGET)_$(TARGET_CPU)_default/lib/libtensorflow-microlite.a\\\n",
        "  -Wl,--fatal-warnings -Wl,--gc-sections --specs=nosys.specs -T \\\n",
        "\t$(THIRD_PARTY)/ethos_u_core_platform/targets/corstone-300/platform_parsed.ld \\\n",
        "\t-Wl,-Map=$(TFLM_ROOT)/tools/make/gen/cortex_m_corstone_300.map,--cref -lm \\\n",
        "\t-Wl,--gc-sections --entry Reset_Handler\n",
        "\n",
        "\n",
        "%.o:\t%.cc\n",
        "\t$(CXX) $(CXXFLAGS) $(INCLUDES) -c $< -o $@\n",
        "\n",
        "all:\tmain.bin\n",
        "\n",
        "all_objs := main.o\n",
        "\n",
        "main:\t$(all_objs)\n",
        "\t$(CXX) $(CXXFLAGS) $(INCLUDES) -o main $(all_objs) $(LDFLAGS)\n",
        "\n",
        "main.bin: main\n",
        "\t$(OBJCOPY) main main.bin -O binary\n",
        "\n",
        "clean:\n",
        "\t$(RM) *.o *.d *.map main.bin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b9oHFLlp_4j"
      },
      "source": [
        "Build the application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkwM46k-Ozoh"
      },
      "outputs": [],
      "source": [
        "!make clean\n",
        "!make -j8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5DoS1mDI1WI"
      },
      "source": [
        "## Deploy application on Corstone-300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhWea6KcqCvs"
      },
      "source": [
        "Run the application in Corstone-300:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "ZEt0YJmYSot9",
        "outputId": "390c1b04-01e3-4798-e2b8-27dd6d0de41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 9: tflite-micro/tensorflow/lite/micro/tools/make/downloads/corstone300/models/Linux64_GCC-6.4/FVP_Corstone_SSE-300_Ethos-U55: No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'\\nFVP=\"tflite-micro/tensorflow/lite/micro/tools/make/downloads/corstone300/models/Linux64_GCC-6.4/FVP_Corstone_SSE-300_Ethos-U55 \"\\nFVP+=\"-C mps3_board.visualisation.disable-visualisation=1 \"\\nFVP+=\"-C mps3_board.telnetterminal0.start_telnet=0 \"\\nFVP+=\\'-C mps3_board.uart0.out_file=\"-\" \\'\\nFVP+=\\'-C mps3_board.uart0.unbuffered_output=1 \\'\\nFVP+=\\'-C mps3_board.uart0.shutdown_on_eot=1\\'\\n\\n$FVP main\\n'' returned non-zero exit status 127.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e42ea16f58d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nFVP=\"tflite-micro/tensorflow/lite/micro/tools/make/downloads/corstone300/models/Linux64_GCC-6.4/FVP_Corstone_SSE-300_Ethos-U55 \"\\nFVP+=\"-C mps3_board.visualisation.disable-visualisation=1 \"\\nFVP+=\"-C mps3_board.telnetterminal0.start_telnet=0 \"\\nFVP+=\\'-C mps3_board.uart0.out_file=\"-\" \\'\\nFVP+=\\'-C mps3_board.uart0.unbuffered_output=1 \\'\\nFVP+=\\'-C mps3_board.uart0.shutdown_on_eot=1\\'\\n\\n$FVP main\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nFVP=\"tflite-micro/tensorflow/lite/micro/tools/make/downloads/corstone300/models/Linux64_GCC-6.4/FVP_Corstone_SSE-300_Ethos-U55 \"\\nFVP+=\"-C mps3_board.visualisation.disable-visualisation=1 \"\\nFVP+=\"-C mps3_board.telnetterminal0.start_telnet=0 \"\\nFVP+=\\'-C mps3_board.uart0.out_file=\"-\" \\'\\nFVP+=\\'-C mps3_board.uart0.unbuffered_output=1 \\'\\nFVP+=\\'-C mps3_board.uart0.shutdown_on_eot=1\\'\\n\\n$FVP main\\n'' returned non-zero exit status 127."
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "FVP=\"tflite-micro/tensorflow/lite/micro/tools/make/downloads/corstone300/models/Linux64_GCC-6.4/FVP_Corstone_SSE-300_Ethos-U55 \"\n",
        "FVP+=\"-C mps3_board.visualisation.disable-visualisation=1 \"\n",
        "FVP+=\"-C mps3_board.telnetterminal0.start_telnet=0 \"\n",
        "FVP+='-C mps3_board.uart0.out_file=\"-\" '\n",
        "FVP+='-C mps3_board.uart0.unbuffered_output=1 '\n",
        "FVP+='-C mps3_board.uart0.shutdown_on_eot=1'\n",
        "\n",
        "$FVP main"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train_and_deploy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}